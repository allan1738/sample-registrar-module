{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "copy of ConCollabo Part1: GPT-2 Train and Inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/allan1738/sample-registrar-module/blob/master/copy_of_ConCollabo_Part1_GPT_2_Train_and_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew5UiXrp3yQK"
      },
      "source": [
        "#  ConCollabo Part 1:\n",
        "## Train a GPT-2 Text-Generating Model with GPU\n",
        "Almost identical to locally training, but since Colab session expires after a few hours, we will take advantage of Google Drive syncing to save checkpoints.\n",
        "\n",
        "*Last updated: July 7th, 2021*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDeMtvDx7-rD"
      },
      "source": [
        "## GPU\n",
        "\n",
        "Change Colab's runtime to use GPU and verify it by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh8Jzp5DrPvU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59f3374c-ef6d-4b4b-f577-1e6ae0ee70f7"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkeAQ2ECdCAC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JnrphytdDN-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y126O4oB8P8-"
      },
      "source": [
        "## Cloning GPT-2\n",
        "\n",
        "Since we are fine-tuning on a new dataset, we need to download the GPT-2 model first. \n",
        "\n",
        "There are three released sizes of GPT-2:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
        "* `774M`: the \"large\" model, cannot currently be finetuned with Colab\n",
        "* `1558M`: the \"extra large\", true model. Will not work if a K80 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
        "\n",
        "The next cell downloads it from Google Cloud Storage and saves it in the Colab VM at `/models/<model_name>`.\n",
        "\n",
        "This model isn't permanently saved in the Colab; we have to redownload it if we want to retrain it at a later time. (After session expires)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04gChmkrqI84",
        "outputId": "5c5f9a12-2d50-434c-a133-0521b102afd3"
      },
      "source": [
        "!git clone https://github.com/nshepperd/gpt-2.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 435, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 435 (delta 19), reused 48 (delta 13), pack-reused 371\u001b[K\n",
            "Receiving objects: 100% (435/435), 4.48 MiB | 23.76 MiB/s, done.\n",
            "Resolving deltas: 100% (220/220), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTK17dvsCgLa",
        "outputId": "1e28028c-e497-4122-eeed-21060b2151fd"
      },
      "source": [
        "cd gpt-2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el9NC68p9FZI"
      },
      "source": [
        "Install prerequisite packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U5MWq-1E5aB",
        "outputId": "f63a6370-c205-437b-9dcf-34bcc058a70a"
      },
      "source": [
        "!python -m pip install -U tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.34.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.32.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (57.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (4.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LAKj6Egq0uS",
        "outputId": "f01d1c22-dd3c-4ba9-8b61-02f3264619f0"
      },
      "source": [
        "!python -m pip install fire regex requests tqdm toposort numpy tensorflow -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▊                            | 10 kB 23.6 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 20 kB 32.9 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 30 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 40 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 51 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 61 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 71 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 81 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 87 kB 4.5 MB/s \n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcMLe3HT9W9U"
      },
      "source": [
        "## Mount Google Drive\n",
        "\n",
        "As mentioned earlier, Colab sessions are not permanent. We can mount Google Drive to retrieve the input data, and as well as output the trained model.\n",
        "\n",
        "Run the cell below to mount our personal Google Drive.\n",
        "(it will ask for an authentication code; the code is not saved anywhere and will be reset when Colab expires/restarts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mhBly2lq2Z6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6e28901-c8fc-4343-a2c4-22c3e238c8f3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "BbHAY3D8l-Uq",
        "outputId": "a9ed2d32-3d31-4dd4-ed6f-2418d36c5aba"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-e4024480c230>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    export GPT2_DIR=/content/drive/MyDrive/Haikus/checkpoint/run1\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5FvDSqNGJPO"
      },
      "source": [
        "## Dataset Preparation\n",
        "\n",
        "Place the dataset file into the cloned \\<gpt-2> folder  \n",
        "This can be any English text. Keep in mind that every sample should end with \\<|endoftext|>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx4SyieEl4yJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5060a011-b3f4-4b31-a5ce-0ea9a8e65229"
      },
      "source": [
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=19Iv70cXYo0cfIPBMvVAN7yRwp9x8966f' -O input.txt\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-30 04:10:03--  https://docs.google.com/uc?export=download&id=19Iv70cXYo0cfIPBMvVAN7yRwp9x8966f\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.127.138, 108.177.127.139, 108.177.127.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.127.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-8s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/06g9tnt7avjghoigsv9v2aep2h5jg7fp/1627618200000/03192608778565483848/*/19Iv70cXYo0cfIPBMvVAN7yRwp9x8966f?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-07-30 04:10:04--  https://doc-04-8s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/06g9tnt7avjghoigsv9v2aep2h5jg7fp/1627618200000/03192608778565483848/*/19Iv70cXYo0cfIPBMvVAN7yRwp9x8966f?e=download\n",
            "Resolving doc-04-8s-docs.googleusercontent.com (doc-04-8s-docs.googleusercontent.com)... 108.177.127.132, 2a00:1450:4013:c07::84\n",
            "Connecting to doc-04-8s-docs.googleusercontent.com (doc-04-8s-docs.googleusercontent.com)|108.177.127.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 923886 (902K) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>] 902.23K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-07-30 04:10:04 (84.4 MB/s) - ‘input.txt’ saved [923886/923886]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTDl5wpS-Mu8"
      },
      "source": [
        "## Train Preparation\n",
        "\n",
        "We need to download the base (pre-trained) GPT-2 model to fine-tune on our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97e2o9Nirpmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c49823a8-f596-41ec-abfb-31eb7b1e0455"
      },
      "source": [
        "!python download_model.py 117M"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'download_model.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJW6R46drrpU"
      },
      "source": [
        "!export PYTHONIOENCODING=UTF-8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKhgOtcu_4Xm"
      },
      "source": [
        "If there are any pre-existing checkpoints in the Google Drive, copy them to the current session to resume training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUtBXR66rtrZ"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/Haikus/checkpoint/ /content/gpt-2/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_guCA4VT_GYc"
      },
      "source": [
        "## Train\n",
        "\n",
        "Run the cell below to start training. The code will automatically save checkpoints every 1,000 steps. \n",
        "\n",
        "To stop training, stop the cell. This will also automatically save the currently stopped checkpoint to \\<gpt-2/checkpoint>\n",
        "\n",
        "To resume training, run this cell again. This will automatically resume training from where we last left off. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rihB3pZtryIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad3581c1-2a53-4970-f632-db698f6ca34a"
      },
      "source": [
        "!PYTHONPATH=src ./train.py --dataset /content/gpt-2/input.txt --model_name '117M'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: ./train.py: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "7CSDOPS0u367",
        "outputId": "605101c6-09bb-41a8-b038-9141caae887b"
      },
      "source": [
        "transformers-cli convert --model_type gpt2 --tf_checkpoint run1 --pytorch_dump_output pytorch --config run1/hparams.json\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-25b32e9dd94d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    transformers-cli convert --model_type gpt2 --tf_checkpoint run1 --pytorch_dump_output pytorch --config run1/hparams.json\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0NEm5X__stP"
      },
      "source": [
        "On Colab, it is recommended to stop training every once in a while to backup checkpoints to the mounted Drive. In the Drive, delete all the previous model files (unless you really need them for history/comparison)\n",
        "\n",
        "\n",
        "\n",
        "*   model-xxx.data-00000-of-00001\n",
        "*   model-xxx.index\n",
        "*   model-xxx.meta\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFAgPpv-whQc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fc42289-60af-4d31-d952-d6bec21dff57"
      },
      "source": [
        "!cp -r /content/gpt-2/checkpoint/run1/ /content/drive/MyDrive/Haiku/checkpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/content/gpt-2/checkpoint/run1/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPH165o7ASld"
      },
      "source": [
        "**bold text**## Inference\n",
        "\n",
        "In order to use our fine-tuned model for inference, we need to copy the latest models to a specific folder \\</content/gpt-2/models/117M/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCAiKD0Rr4vM"
      },
      "source": [
        "!cp -r /content/gpt-2/checkpoint/run1/* /content/gpt-2/models/117M/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKOy8zqSBUDn"
      },
      "source": [
        "For inference, run the following cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQP9qndVr_g0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c945737e-0100-4309-f9e9-5d527c779351"
      },
      "source": [
        "!python src/interactive_conditional_samples.py --nsamples=1 --top_k 40 --top_p 40 --temperature 0.01 --model_name \"117M\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-29 15:13:20.859243: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-29 15:13:22.957280: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-29 15:13:23.016377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 15:13:23.017007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-29 15:13:23.017065: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-29 15:13:23.153377: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-29 15:13:23.153494: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-29 15:13:23.300793: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-29 15:13:23.346879: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-29 15:13:23.594155: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-29 15:13:23.633602: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-29 15:13:23.642327: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-29 15:13:23.642488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 15:13:23.643130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 15:13:23.646396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-07-29 15:13:23.656314: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-07-29 15:13:23.656592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 15:13:23.657179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-29 15:13:23.657285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 15:13:23.657847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 15:13:23.658391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-07-29 15:13:23.660620: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-29 15:13:28.672961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-29 15:13:28.673047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-07-29 15:13:28.673065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-07-29 15:13:28.673257: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 15:13:28.673864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 15:13:28.674449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 15:13:28.674985: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-29 15:13:28.675058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13837 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:60: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "2021-07-29 15:13:32.269921: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2000155000 Hz\n",
            "Model prompt >>> summer sunset night\n",
            "2021-07-29 15:17:28.941268: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-29 15:17:31.484041: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "======================================== SAMPLE 1 ========================================\n",
            "\n",
            "<|endoftext|>\n",
            "\n",
            "the weathered wheel\n",
            "still inviting\n",
            "our thoughts\n",
            "<|endoftext|>\n",
            "\n",
            "a rusted truck\n",
            "the meadowlark\n",
            "keeps calling\n",
            "<|endoftext|>\n",
            "\n",
            "trail spur?\n",
            "in the leafless meadow\n",
            "ferns, lichen\n",
            "<|endoftext|>\n",
            "\n",
            "daylight savings\n",
            "the glimmer of a penny\n",
            "in the sand\n",
            "<|endoftext|>\n",
            "\n",
            "splatting sparrow\n",
            "my thoughts my scent\n",
            "a yellow flower\n",
            "<|endoftext|>\n",
            "\n",
            "sunrise\n",
            "and then the gurgle\n",
            "of maples\n",
            "<|endoftext|>\n",
            "\n",
            "youngonia\n",
            "her garden gnome's\n",
            "shape of eyes\n",
            "<|endoftext|>\n",
            "\n",
            "the old log\n",
            "since the pond\n",
            "will never dry\n",
            "<|endoftext|>\n",
            "\n",
            "puddle?\n",
            "a mosquito lands\n",
            "on my shoe\n",
            "<|endoftext|>\n",
            "\n",
            "legged?\n",
            "a lego doll\n",
            "creaks on the floor\n",
            "<|endoftext|>\n",
            "\n",
            "leaving the pond\n",
            "swollen eyes\n",
            "of a dog\n",
            "<|endoftext|>\n",
            "\n",
            "jumping rope\n",
            "a part of me feels\n",
            "right at home\n",
            "<|endoftext|>\n",
            "\n",
            "end of summer\n",
            "hopscotch clears the crest\n",
            "of the loon\n",
            "<|endoftext|>\n",
            "\n",
            "heather blooms\n",
            "he glides them over\n",
            "the mosquito net\n",
            "<|endoftext|>\n",
            "\n",
            "the dog takes a sniff\n",
            "sound of the rain\n",
            "in the trees\n",
            "<|endoftext|>\n",
            "\n",
            "cloud shadow?\n",
            "he gently folds\n",
            "the bluebird feather\n",
            "<|endoftext|>\n",
            "\n",
            "moorland path\n",
            "the way it turns\n",
            "into a trail\n",
            "<|endoftext|>\n",
            "\n",
            "fine mist\n",
            "pigeons occupy\n",
            "every nook\n",
            "<|endoftext|>\n",
            "\n",
            "the bay\n",
            "one feather\n",
            "soaks the grass\n",
            "<|endoftext|>\n",
            "\n",
            "blue-eyed grass\n",
            "the blue-eyed cat\n",
            "gathers his nest\n",
            "<|endoftext|>\n",
            "\n",
            "kids, can't believe\n",
            "these clouds drift here and there\n",
            "in the blue sky\n",
            "<|endoftext|>\n",
            "\n",
            "harvest moon . . .\n",
            "garden's edge dips\n",
            "into\n",
            "================================================================================\n",
            "Model prompt >>> love for books\n",
            "======================================== SAMPLE 1 ========================================\n",
            "\n",
            "<|endoftext|>\n",
            "\n",
            "the old ways\n",
            "the way it used to be\n",
            "<|endoftext|>\n",
            "\n",
            "summer heat\n",
            "the sound of a bookhelider\n",
            "lifting\n",
            "<|endoftext|>\n",
            "\n",
            "shimmering fireflies\n",
            "amid roadside traffic\n",
            "this summer night\n",
            "<|endoftext|>\n",
            "\n",
            "in the hour ahead\n",
            "crystalline night\n",
            "spanish chestnuts\n",
            "<|endoftext|>\n",
            "\n",
            "a moment\n",
            "behind the scenes\n",
            "the deep history\n",
            "<|endoftext|>\n",
            "\n",
            "cathedral tour\n",
            "the wildness\n",
            "of new-born calves\n",
            "<|endoftext|>\n",
            "\n",
            "dusk -\n",
            "the bright stars shining\n",
            "from every window\n",
            "<|endoftext|>\n",
            "\n",
            "lit by the blue sky\n",
            "a dungeoneer sings\n",
            "his way home\n",
            "<|endoftext|>\n",
            "\n",
            "gala garden\n",
            "the one-note squeak\n",
            "of rain\n",
            "<|endoftext|>\n",
            "\n",
            "with a little rain,\n",
            "the (one-note squeak)\n",
            "of rain\n",
            "<|endoftext|>\n",
            "\n",
            "picking up\n",
            "a medicine jarful\n",
            "october moon\n",
            "<|endoftext|>\n",
            "\n",
            "at the cemetery gate\n",
            "her breath\n",
            "on the stone steps\n",
            "<|endoftext|>\n",
            "\n",
            "her grave\n",
            "every time\n",
            "our breaths\n",
            "<|endoftext|>\n",
            "\n",
            "fine mist\n",
            "silver frost\n",
            "on the onion field\n",
            "<|endoftext|>\n",
            "\n",
            "fine mist\n",
            "the scent of rain\n",
            "clings to pots\n",
            "<|endoftext|>\n",
            "\n",
            "fine mist\n",
            "the basso cardi search\n",
            "for a poem\n",
            "<|endoftext|>\n",
            "\n",
            "onion skins\n",
            "the sound of a shoemaker\n",
            "\n",
            "in the furnace\n",
            "<|endoftext|>\n",
            "\n",
            "fire at dusk\n",
            "the scent of Iowa\n",
            "fills the street\n",
            "<|endoftext|>\n",
            "\n",
            "middle of the night\n",
            "my eyes on the white\n",
            "of the wall\n",
            "<|endoftext|>\n",
            "\n",
            "frost moon\n",
            "the kitten takes\n",
            "the winter bath\n",
            "<|endoftext|>\n",
            "\n",
            "oak leaves\n",
            "steeping\n",
            "night winds\n",
            "<|endoftext|>\n",
            "\n",
            "leap year\n",
            "clapper off the cliff\n",
            "airport wait time\n",
            "<|endoftext|>\n",
            "\n",
            "high summer\n",
            "clouds the river\n",
            "wind\n",
            "================================================================================\n",
            "Model prompt >>> great lakes today\n",
            "======================================== SAMPLE 1 ========================================\n",
            "\n",
            "<|endoftext|>\n",
            "\n",
            "the old ways\n",
            "the way it ended\n",
            "<|endoftext|>\n",
            "\n",
            "roadside rest stop\n",
            "he adds a haiku\n",
            "to the graffiti\n",
            "<|endoftext|>\n",
            "\n",
            "trail spur marker\n",
            "my brother and i meet\n",
            "the first flying squirrel\n",
            "<|endoftext|>\n",
            "\n",
            "her passing\n",
            "the white pines\n",
            "of the blue damselflies\n",
            "<|endoftext|>\n",
            "\n",
            "men playing\n",
            "nearly black ink\n",
            "in the snowmelt\n",
            "<|endoftext|>\n",
            "\n",
            "the dog just\n",
            "kneaded a withered tree\n",
            "revival summer\n",
            "<|endoftext|>\n",
            "\n",
            "our pass\n",
            "the wind lifts it\n",
            "high into the air\n",
            "<|endoftext|>\n",
            "\n",
            "wisps of fog\n",
            "her long hair points the way\n",
            "to the bitter end\n",
            "<|endoftext|>\n",
            "\n",
            "summer clouds\n",
            "the final push\n",
            "of a laboring bison\n",
            "<|endoftext|>\n",
            "\n",
            "i gather my thoughts\n",
            "about the long walk\n",
            "chrysanovski\n",
            "<|endoftext|>\n",
            "\n",
            "dreary day\n",
            "someone at the spade augh\n",
            "to certain death\n",
            "<|endoftext|>\n",
            "\n",
            "ather snow\n",
            "a little breath\n",
            "needed to cool\n",
            "<|endoftext|>\n",
            "\n",
            "new year's day\n",
            "an old war veteran\n",
            "sharing\n",
            "<|endoftext|>\n",
            "\n",
            "starry night\n",
            "i?ll die\n",
            "the old roses\n",
            "<|endoftext|>\n",
            "\n",
            "raining\n",
            "morning meditation\n",
            "in the subway\n",
            "<|endoftext|>\n",
            "\n",
            "sunrise\n",
            "in the form\n",
            "of pineapples\n",
            "<|endoftext|>\n",
            "\n",
            "summer rain\n",
            "her christmas lights\n",
            "outshine mine\n",
            "<|endoftext|>\n",
            "\n",
            "sudden rain\n",
            "the blur of crows\n",
            "through a hall\n",
            "<|endoftext|>\n",
            "\n",
            "winter sunshine\n",
            "the perfect circles\n",
            "of a horse & donkey\n",
            "<|endoftext|>\n",
            "\n",
            "first snow\n",
            "on the snowman's coat\n",
            "the white glow\n",
            "<|endoftext|>\n",
            "\n",
            "christmas dinner\n",
            "the fifth burner\n",
            "fires\n",
            "<|endoftext|>\n",
            "\n",
            "the cool flight\n",
            "of a passing cormorant\n",
            "new year's day\n",
            "<|endoftext|>\n",
            "\n",
            "fleeting\n",
            "================================================================================\n",
            "Model prompt >>> Traceback (most recent call last):\n",
            "  File \"src/interactive_conditional_samples.py\", line 73, in interact_model\n",
            "    raw_text = input(\"Model prompt >>> \")\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"src/interactive_conditional_samples.py\", line 91, in <module>\n",
            "    fire.Fire(interact_model)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 141, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 471, in _Fire\n",
            "    target=component.__name__)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 681, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"src/interactive_conditional_samples.py\", line 88, in interact_model\n",
            "    print(\"=\" * 80)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 1613, in __exit__\n",
            "    def __exit__(self, exec_type, exec_value, exec_tb):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqLRvIEQBdbs"
      },
      "source": [
        "Run the cell below to see all the adjustable flags/options."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te5QlCTwsGbo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14cc00f1-8a98-476c-d84b-c863d0e82496"
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py -- --help"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'src/interactive_conditional_samples.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}